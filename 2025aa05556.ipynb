{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2495857,"sourceType":"datasetVersion","datasetId":1511119},{"sourceId":14850114,"sourceType":"datasetVersion","datasetId":9498416}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split,cross_val_score, StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\ntry:\n    from xgboost import XGBClassifier\n    XGBOOST_AVAILABLE = True\nexcept ImportError:\n    print(\"XGBoost not available - will use GradientBoosting as alternative\")\n    from sklearn.ensemble import GradientBoostingClassifier\n    XGBOOST_AVAILABLE = False\nfrom sklearn.metrics import (accuracy_score, roc_auc_score, precision_score,\n                             recall_score, f1_score, matthews_corrcoef,\n                             confusion_matrix, classification_report)\nimport pickle\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"3YBmcGV3eMOv","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:34.778920Z","iopub.execute_input":"2026-02-15T17:10:34.780030Z","iopub.status.idle":"2026-02-15T17:10:34.787611Z","shell.execute_reply.started":"2026-02-15T17:10:34.779998Z","shell.execute_reply":"2026-02-15T17:10:34.786514Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"import os\n\nfor dirname, f, filenames in os.walk('/kaggle'):\n    for filename in filenames:\n        print(f)\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:38.783289Z","iopub.execute_input":"2026-02-15T17:10:38.784154Z","iopub.status.idle":"2026-02-15T17:10:38.805064Z","shell.execute_reply.started":"2026-02-15T17:10:38.784122Z","shell.execute_reply":"2026-02-15T17:10:38.804000Z"}},"outputs":[{"name":"stdout","text":"[]\n/kaggle/lib/kaggle/gcp.py\n[]\n/kaggle/input/datasets/saikatkumar/heart-disease-dataset-uci-new/HeartDiseaseTrain-Test.csv\n[]\n/kaggle/input/datasets/ketangangal/heart-disease-dataset-uci/HeartDiseaseTrain-Test.csv\n['.virtual_documents']\n/kaggle/working/model_xgboost.pkl\n['.virtual_documents']\n/kaggle/working/model_knn.pkl\n['.virtual_documents']\n/kaggle/working/model_comparison.csv\n['.virtual_documents']\n/kaggle/working/model_logistic_regression.pkl\n['.virtual_documents']\n/kaggle/working/model_random_forest.pkl\n['.virtual_documents']\n/kaggle/working/heart_disease_test.csv\n['.virtual_documents']\n/kaggle/working/scaler.pkl\n['.virtual_documents']\n/kaggle/working/label_encoders.pkl\n['.virtual_documents']\n/kaggle/working/model_naive_bayes.pkl\n['.virtual_documents']\n/kaggle/working/model_decision_tree.pkl\n[]\n/kaggle/working/.virtual_documents/__notebook_source__.ipynb\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Load the dataset\nprint(\"Loading dataset...\")\ndf = pd.read_csv(\"/kaggle/input/datasets/saikatkumar/heart-disease-dataset-uci-new/HeartDiseaseTrain-Test.csv\")\nprint(f\"Dataset shape: {df.shape}\")\nprint(f\"\\nFirst few rows:\\n{df.head()}\")\nprint(f\"\\nDataset info:\")\nprint(df.info())\nprint(f\"\\nMissing values:\\n{df.isnull().sum()}\")\nprint(f\"\\nTarget distribution:\\n{df['target'].value_counts()}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-d4HyRYQruo2","outputId":"98d2ebb8-4e81-4440-b469-e230a1ee0613","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:48.014606Z","iopub.execute_input":"2026-02-15T17:10:48.014937Z","iopub.status.idle":"2026-02-15T17:10:48.052659Z","shell.execute_reply.started":"2026-02-15T17:10:48.014903Z","shell.execute_reply":"2026-02-15T17:10:48.051540Z"}},"outputs":[{"name":"stdout","text":"Loading dataset...\nDataset shape: (1025, 14)\n\nFirst few rows:\n   age     sex chest_pain_type  resting_blood_pressure  cholestoral  \\\n0   52    Male  Typical angina                     125          212   \n1   53    Male  Typical angina                     140          203   \n2   70    Male  Typical angina                     145          174   \n3   61    Male  Typical angina                     148          203   \n4   62  Female  Typical angina                     138          294   \n\n      fasting_blood_sugar               rest_ecg  Max_heart_rate  \\\n0    Lower than 120 mg/ml  ST-T wave abnormality             168   \n1  Greater than 120 mg/ml                 Normal             155   \n2    Lower than 120 mg/ml  ST-T wave abnormality             125   \n3    Lower than 120 mg/ml  ST-T wave abnormality             161   \n4  Greater than 120 mg/ml  ST-T wave abnormality             106   \n\n  exercise_induced_angina  oldpeak        slope vessels_colored_by_flourosopy  \\\n0                      No      1.0  Downsloping                           Two   \n1                     Yes      3.1    Upsloping                          Zero   \n2                     Yes      2.6    Upsloping                          Zero   \n3                      No      0.0  Downsloping                           One   \n4                      No      1.9         Flat                         Three   \n\n         thalassemia  target  \n0  Reversable Defect       0  \n1  Reversable Defect       0  \n2  Reversable Defect       0  \n3  Reversable Defect       0  \n4       Fixed Defect       0  \n\nDataset info:\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1025 entries, 0 to 1024\nData columns (total 14 columns):\n #   Column                         Non-Null Count  Dtype  \n---  ------                         --------------  -----  \n 0   age                            1025 non-null   int64  \n 1   sex                            1025 non-null   object \n 2   chest_pain_type                1025 non-null   object \n 3   resting_blood_pressure         1025 non-null   int64  \n 4   cholestoral                    1025 non-null   int64  \n 5   fasting_blood_sugar            1025 non-null   object \n 6   rest_ecg                       1025 non-null   object \n 7   Max_heart_rate                 1025 non-null   int64  \n 8   exercise_induced_angina        1025 non-null   object \n 9   oldpeak                        1025 non-null   float64\n 10  slope                          1025 non-null   object \n 11  vessels_colored_by_flourosopy  1025 non-null   object \n 12  thalassemia                    1025 non-null   object \n 13  target                         1025 non-null   int64  \ndtypes: float64(1), int64(5), object(8)\nmemory usage: 112.2+ KB\nNone\n\nMissing values:\nage                              0\nsex                              0\nchest_pain_type                  0\nresting_blood_pressure           0\ncholestoral                      0\nfasting_blood_sugar              0\nrest_ecg                         0\nMax_heart_rate                   0\nexercise_induced_angina          0\noldpeak                          0\nslope                            0\nvessels_colored_by_flourosopy    0\nthalassemia                      0\ntarget                           0\ndtype: int64\n\nTarget distribution:\ntarget\n1    526\n0    499\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"# Data Preprocessing\nprint(\"\\n\" + \"=\"*50)\nprint(\"PREPROCESSING DATA\")\nprint(\"=\"*50)\ncategorical_cols = df.select_dtypes(include=['object']).columns.tolist()\nnumerical_cols = df.select_dtypes(include=['int64', 'float64']).columns.tolist()\nnumerical_cols.remove('target')  # Remove target from numerical columns\n\nprint(f\"\\nCategorical columns: {categorical_cols}\")\nprint(f\"Numerical columns: {numerical_cols}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XGfVJcTBr7yc","outputId":"20281efd-b980-4b41-b6e4-f039ed3ef901","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:51.059123Z","iopub.execute_input":"2026-02-15T17:10:51.059725Z","iopub.status.idle":"2026-02-15T17:10:51.068160Z","shell.execute_reply.started":"2026-02-15T17:10:51.059679Z","shell.execute_reply":"2026-02-15T17:10:51.066801Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nPREPROCESSING DATA\n==================================================\n\nCategorical columns: ['sex', 'chest_pain_type', 'fasting_blood_sugar', 'rest_ecg', 'exercise_induced_angina', 'slope', 'vessels_colored_by_flourosopy', 'thalassemia']\nNumerical columns: ['age', 'resting_blood_pressure', 'cholestoral', 'Max_heart_rate', 'oldpeak']\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"label_encoders = {}\nfor col in categorical_cols:\n    le = LabelEncoder()\n    df[col] = le.fit_transform(df[col])\n    label_encoders[col] = le","metadata":{"id":"QSbgiQfvsnyy","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:52.133916Z","iopub.execute_input":"2026-02-15T17:10:52.134406Z","iopub.status.idle":"2026-02-15T17:10:52.146036Z","shell.execute_reply.started":"2026-02-15T17:10:52.134375Z","shell.execute_reply":"2026-02-15T17:10:52.144554Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"X = df.drop('target', axis=1)\ny = df['target']","metadata":{"id":"9VP39bJ8srIF","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:53.583533Z","iopub.execute_input":"2026-02-15T17:10:53.583850Z","iopub.status.idle":"2026-02-15T17:10:53.590965Z","shell.execute_reply.started":"2026-02-15T17:10:53.583826Z","shell.execute_reply":"2026-02-15T17:10:53.589874Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","metadata":{"id":"Qu85PcZZstQE","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:55.129017Z","iopub.execute_input":"2026-02-15T17:10:55.130035Z","iopub.status.idle":"2026-02-15T17:10:55.140490Z","shell.execute_reply.started":"2026-02-15T17:10:55.129998Z","shell.execute_reply":"2026-02-15T17:10:55.139344Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"print(f\"\\nTraining set size: {X_train.shape[0]}\")\nprint(f\"Test set size: {X_test.shape[0]}\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rxo82QRjswMF","outputId":"c30046fa-04d0-46ad-d171-515c9783cfa3","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:56.338906Z","iopub.execute_input":"2026-02-15T17:10:56.339280Z","iopub.status.idle":"2026-02-15T17:10:56.345667Z","shell.execute_reply.started":"2026-02-15T17:10:56.339252Z","shell.execute_reply":"2026-02-15T17:10:56.344307Z"}},"outputs":[{"name":"stdout","text":"\nTraining set size: 820\nTest set size: 205\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","metadata":{"id":"KTbohl_cs9A5","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:58.368731Z","iopub.execute_input":"2026-02-15T17:10:58.369091Z","iopub.status.idle":"2026-02-15T17:10:58.384400Z","shell.execute_reply.started":"2026-02-15T17:10:58.369063Z","shell.execute_reply":"2026-02-15T17:10:58.383145Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"test_data = X_test.copy()\ntest_data['target'] = y_test\ntest_data.to_csv('heart_disease_test.csv', index=False)\nprint(\"\\nTest data saved as 'heart_disease_test.csv'\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NxrOA1WjtDqM","outputId":"1c44bd13-dda3-4f95-e45c-fcb6ee572d96","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:10:59.693638Z","iopub.execute_input":"2026-02-15T17:10:59.694880Z","iopub.status.idle":"2026-02-15T17:10:59.706604Z","shell.execute_reply.started":"2026-02-15T17:10:59.694820Z","shell.execute_reply":"2026-02-15T17:10:59.705275Z"}},"outputs":[{"name":"stdout","text":"\nTest data saved as 'heart_disease_test.csv'\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"with open('scaler.pkl', 'wb') as f:\n    pickle.dump(scaler, f)\nwith open('label_encoders.pkl', 'wb') as f:\n    pickle.dump(label_encoders, f)\n","metadata":{"id":"YTpPtpWWtGfH","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:11:01.613776Z","iopub.execute_input":"2026-02-15T17:11:01.614678Z","iopub.status.idle":"2026-02-15T17:11:01.621504Z","shell.execute_reply.started":"2026-02-15T17:11:01.614645Z","shell.execute_reply":"2026-02-15T17:11:01.620389Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"# Initialize models\nmodels = {\n    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n    'Decision Tree': DecisionTreeClassifier(random_state=42,max_depth=10,min_samples_split=10,min_samples_leaf=5),\n    'kNN': KNeighborsClassifier(n_neighbors=5),\n    'Naive Bayes': GaussianNB(),\n    'Random Forest': RandomForestClassifier(n_estimators=70, max_depth=15,min_samples_split=8, min_samples_leaf=6,max_features='sqrt',random_state=42)\n}\n\n\nif XGBOOST_AVAILABLE:\n    models['XGBoost'] = XGBClassifier(n_estimators=70,random_state=42,max_depth=3,learning_rate=0.05)\nelse:\n    models['XGBoost'] = GradientBoostingClassifier(n_estimators=70,random_state=42,max_depth=3,learning_rate=0.05)\n    print(\"\\nNote: Using GradientBoostingClassifier instead of XGBoost\")\n","metadata":{"id":"yOLSWbeVtJEx","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:11:03.250392Z","iopub.execute_input":"2026-02-15T17:11:03.251559Z","iopub.status.idle":"2026-02-15T17:11:03.259130Z","shell.execute_reply.started":"2026-02-15T17:11:03.251516Z","shell.execute_reply":"2026-02-15T17:11:03.257720Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"results = []","metadata":{"id":"G9bWcVimtSF0","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:11:05.478347Z","iopub.execute_input":"2026-02-15T17:11:05.478747Z","iopub.status.idle":"2026-02-15T17:11:05.484003Z","shell.execute_reply.started":"2026-02-15T17:11:05.478717Z","shell.execute_reply":"2026-02-15T17:11:05.482963Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"TRAINING AND EVALUATING MODELS\")\nprint(\"=\"*50)\n\nfor model_name, model in models.items():\n    print(f\"\\n{'='*50}\")\n    print(f\"Training {model_name}...\")\n    print(f\"{'='*50}\")\n\n    model.fit(X_train_scaled, y_train)\n    test_acc = model.score(X_test_scaled, y_test)\n\n    # Make predictions\n    y_pred = model.predict(X_test_scaled)\n    y_pred_proba = model.predict_proba(X_test_scaled)[:, 1]\n\n    # Calculate metrics\n    accuracy = accuracy_score(y_test, y_pred)\n    auc = roc_auc_score(y_test, y_pred_proba)\n    precision = precision_score(y_test, y_pred, average='binary')\n    recall = recall_score(y_test, y_pred, average='binary')\n    f1 = f1_score(y_test, y_pred, average='binary')\n    mcc = matthews_corrcoef(y_test, y_pred)\n\n    print(f\"Accuracy: {accuracy:.4f}\")\n    print(f\"AUC Score: {auc:.4f}\")\n    print(f\"Precision: {precision:.4f}\")\n    print(f\"Recall: {recall:.4f}\")\n    print(f\"F1 Score: {f1:.4f}\")\n    print(f\"MCC Score: {mcc:.4f}\")\n\n    # Store results\n    results.append({\n        'Model': model_name,\n        'Accuracy': accuracy,\n        'AUC': auc,\n        'Precision': precision,\n        'Recall': recall,\n        'F1': f1,\n        'MCC': mcc\n    })\n\n    # Save the trained model\n    model_filename = f\"model_{model_name.replace(' ', '_').lower()}.pkl\"\n    with open(model_filename, 'wb') as f:\n        pickle.dump(model, f)\n    print(f\"Model saved as {model_filename}\")\n\nresults_df = pd.DataFrame(results)\nprint(\"\\n\" + \"=\"*50)\nprint(\"FINAL RESULTS COMPARISON\")\nprint(\"=\"*50)\nprint(results_df.to_string(index=False))\n\n# Save results to CSV\nresults_df.to_csv('model_comparison.csv', index=False)\nprint(\"\\nResults saved to 'model_comparison.csv'\")\n\n\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1jTFJommtXG0","outputId":"63e02001-5a47-484b-8803-75cb83b1ce6a","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:11:07.778947Z","iopub.execute_input":"2026-02-15T17:11:07.779431Z","iopub.status.idle":"2026-02-15T17:11:08.167211Z","shell.execute_reply.started":"2026-02-15T17:11:07.779373Z","shell.execute_reply":"2026-02-15T17:11:08.165647Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nTRAINING AND EVALUATING MODELS\n==================================================\n\n==================================================\nTraining Logistic Regression...\n==================================================\nAccuracy: 0.8439\nAUC Score: 0.9320\nPrecision: 0.8230\nRecall: 0.8857\nF1 Score: 0.8532\nMCC Score: 0.6891\nModel saved as model_logistic_regression.pkl\n\n==================================================\nTraining Decision Tree...\n==================================================\nAccuracy: 0.9366\nAUC Score: 0.9885\nPrecision: 0.9510\nRecall: 0.9238\nF1 Score: 0.9372\nMCC Score: 0.8736\nModel saved as model_decision_tree.pkl\n\n==================================================\nTraining kNN...\n==================================================\nAccuracy: 0.8634\nAUC Score: 0.9689\nPrecision: 0.8598\nRecall: 0.8762\nF1 Score: 0.8679\nMCC Score: 0.7267\nModel saved as model_knn.pkl\n\n==================================================\nTraining Naive Bayes...\n==================================================\nAccuracy: 0.8439\nAUC Score: 0.9135\nPrecision: 0.8288\nRecall: 0.8762\nF1 Score: 0.8519\nMCC Score: 0.6884\nModel saved as model_naive_bayes.pkl\n\n==================================================\nTraining Random Forest...\n==================================================\nAccuracy: 0.9415\nAUC Score: 0.9847\nPrecision: 0.9189\nRecall: 0.9714\nF1 Score: 0.9444\nMCC Score: 0.8842\nModel saved as model_random_forest.pkl\n\n==================================================\nTraining XGBoost...\n==================================================\nAccuracy: 0.9073\nAUC Score: 0.9677\nPrecision: 0.8772\nRecall: 0.9524\nF1 Score: 0.9132\nMCC Score: 0.8173\nModel saved as model_xgboost.pkl\n\n==================================================\nFINAL RESULTS COMPARISON\n==================================================\n              Model  Accuracy      AUC  Precision   Recall       F1      MCC\nLogistic Regression  0.843902 0.932000   0.823009 0.885714 0.853211 0.689136\n      Decision Tree  0.936585 0.988476   0.950980 0.923810 0.937198 0.873560\n                kNN  0.863415 0.968905   0.859813 0.876190 0.867925 0.726675\n        Naive Bayes  0.843902 0.913524   0.828829 0.876190 0.851852 0.688357\n      Random Forest  0.941463 0.984667   0.918919 0.971429 0.944444 0.884212\n            XGBoost  0.907317 0.967714   0.877193 0.952381 0.913242 0.817300\n\nResults saved to 'model_comparison.csv'\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"print(\"\\n\" + \"=\"*50)\nprint(\"MODEL PERFORMANCE OBSERVATIONS\")\nprint(\"=\"*50)\n\nobservations = []\n\nfor _, row in results_df.iterrows():\n    model = row['Model']\n    acc = row['Accuracy']\n    auc = row['AUC']\n    f1 = row['F1']\n    mcc = row['MCC']\n\n    # Generate observation based on performance\n    if acc >= 0.85 and auc >= 0.90:\n        obs = f\"Excellent performance with high accuracy ({acc:.3f}) and AUC ({auc:.3f}). Well-balanced model suitable for deployment.\"\n    elif acc >= 0.80:\n        obs = f\"Good performance with accuracy of {acc:.3f} and AUC of {auc:.3f}. Reliable predictions with balanced precision-recall.\"\n    elif acc >= 0.75:\n        obs = f\"Moderate performance with accuracy of {acc:.3f}. May need hyperparameter tuning or feature engineering for improvement.\"\n    else:\n        obs = f\"Below average performance (accuracy: {acc:.3f}). Consider different algorithms or data preprocessing strategies.\"\n\n    observations.append({'Model': model, 'Observation': obs})\n    print(f\"\\n{model}:\")\n    print(f\"  {obs}\")\n\n# Save observations\nobs_df = pd.DataFrame(observations)\nobs_df.to_csv('model_observations.csv', index=False)\n\nprint(\"\\n\" + \"=\"*50)\nprint(\"TRAINING COMPLETE!\")\nprint(\"=\"*50)\nprint(\"\\nGenerated files:\")\nprint(\"  - model_*.pkl (6 trained models)\")\nprint(\"  - scaler.pkl (feature scaler)\")\nprint(\"  - label_encoders.pkl (categorical encoders)\")\nprint(\"  - heart_disease_test.csv (test dataset for Streamlit)\")\nprint(\"  - model_comparison.csv (evaluation results)\")\nprint(\"  - model_observations.csv (performance observations)\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kW3YAP1Ptcio","outputId":"4617dcfd-e3a0-4359-bab3-11ffce8dfb58","trusted":true,"execution":{"iopub.status.busy":"2026-02-15T17:11:32.454542Z","iopub.execute_input":"2026-02-15T17:11:32.455785Z","iopub.status.idle":"2026-02-15T17:11:32.471722Z","shell.execute_reply.started":"2026-02-15T17:11:32.455733Z","shell.execute_reply":"2026-02-15T17:11:32.470797Z"}},"outputs":[{"name":"stdout","text":"\n==================================================\nMODEL PERFORMANCE OBSERVATIONS\n==================================================\n\nLogistic Regression:\n  Good performance with accuracy of 0.844 and AUC of 0.932. Reliable predictions with balanced precision-recall.\n\nDecision Tree:\n  Excellent performance with high accuracy (0.937) and AUC (0.988). Well-balanced model suitable for deployment.\n\nkNN:\n  Excellent performance with high accuracy (0.863) and AUC (0.969). Well-balanced model suitable for deployment.\n\nNaive Bayes:\n  Good performance with accuracy of 0.844 and AUC of 0.914. Reliable predictions with balanced precision-recall.\n\nRandom Forest:\n  Excellent performance with high accuracy (0.941) and AUC (0.985). Well-balanced model suitable for deployment.\n\nXGBoost:\n  Excellent performance with high accuracy (0.907) and AUC (0.968). Well-balanced model suitable for deployment.\n\n==================================================\nTRAINING COMPLETE!\n==================================================\n\nGenerated files:\n  - model_*.pkl (6 trained models)\n  - scaler.pkl (feature scaler)\n  - label_encoders.pkl (categorical encoders)\n  - heart_disease_test.csv (test dataset for Streamlit)\n  - model_comparison.csv (evaluation results)\n  - model_observations.csv (performance observations)\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"","metadata":{"id":"efKOIIqIuHjA"},"outputs":[],"execution_count":null}]}